{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30b65825-f412-4acf-bc6f-b19cd5bc76c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builds the eval dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d35d9afa-dac7-49c0-900a-db66657407b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient, Collection\n",
    "from llama_index.vector_stores.milvus import MilvusVectorStore\n",
    "from llama_index.core import Settings\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "import random as rnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ff8bf99-1465-4f2f-96a6-2aaa485e89a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = MilvusVectorStore(\n",
    "    uri=\"/Users/Zhiyuan/Project/rag_projects/my-web-novel/cache/db/milvus.db\", collection_name='create_eval_dataset_collections_hybrid'\n",
    ")\n",
    "client = vector_store.client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b10dde06-d1a3-4ac3-8353-3dd86a74211c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed model\n",
    "embed_model = HuggingFaceEmbedding(model_name='/Users/Zhiyuan/Project/hf/bge-m3', embed_batch_size=1024)\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68369708-ba5b-454c-b818-8a89f8f11d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfa3a46c\n",
      "06ad4aec\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "print(hashlib.sha1('凡人修仙传.txt'.encode('utf-8')).hexdigest()[:8])\n",
    "print(hashlib.sha1('凡人修仙之仙界篇.txt'.encode('utf-8')).hexdigest()[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "30105dba-58ba-45d6-89c2-58faf960f636",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "654ea4cf-a0bc-4033-a6aa-0e8b776f3535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'collection_name': 'create_eval_dataset_collections_hybrid',\n",
       " 'auto_id': False,\n",
       " 'num_shards': 0,\n",
       " 'description': '',\n",
       " 'fields': [{'field_id': 100,\n",
       "   'name': 'id',\n",
       "   'description': '',\n",
       "   'type': <DataType.VARCHAR: 21>,\n",
       "   'params': {'max_length': 65535},\n",
       "   'is_primary': True},\n",
       "  {'field_id': 101,\n",
       "   'name': 'embedding',\n",
       "   'description': '',\n",
       "   'type': <DataType.FLOAT_VECTOR: 101>,\n",
       "   'params': {'dim': 1024}},\n",
       "  {'field_id': 102,\n",
       "   'name': 'sparse_embedding',\n",
       "   'description': '',\n",
       "   'type': <DataType.SPARSE_FLOAT_VECTOR: 104>,\n",
       "   'params': {}}],\n",
       " 'functions': [],\n",
       " 'aliases': [],\n",
       " 'collection_id': 0,\n",
       " 'consistency_level': 0,\n",
       " 'properties': {},\n",
       " 'num_partitions': 0,\n",
       " 'enable_dynamic_field': True}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.describe_collection('create_eval_dataset_collections_hybrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93692593-1988-49bb-bb28-efbd840aedb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfa3a46c00000000 -> dfa3a46c00011095\n",
    "# 06ad4aec00000000 -> 06ad4aec00006915"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9da90312-2b5b-4125-8118-03a85b1ab7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_builder_example(content):\n",
    "    messages = [{\"role\": \"system\", \"content\": \"你是一个武侠传记作家.\"}, {\"role\": \"user\", \"content\": content}]\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c13463dc-7dcc-49f9-aac2-3fce364c12a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import copy\n",
    "import uuid\n",
    "format_basic = {'idx': \"\", 'question':\"\", 'answer':\"\", \"nodes\":[], \"context\":[]}\n",
    "prefix = 'dfa3a46c'\n",
    "with open('eval_dataset_text_basic.jsonl', 'w', encoding='utf-8') as fw:\n",
    "    with open('eval_dataset_text_basic.qwen.jsonl', 'w', encoding='utf-8') as fout:\n",
    "        prefix = 'dfa3a46c'\n",
    "        for _ in range(100):\n",
    "            start_idx = rnd.randint(0, 11095)\n",
    "            id_ = prefix+str(start_idx).zfill(8)\n",
    "            res = client.query(\n",
    "                collection_name=\"create_eval_dataset_collections\",\n",
    "                filter=f\"id like \\'{id_[:-2]}%\\'\"\n",
    "            )\n",
    "            ss = rnd.randint(1,45)\n",
    "            context_pool = [res[i] for i in range(ss, ss+rnd.randint(1,50))]\n",
    "            row_ = copy.deepcopy(format_basic)\n",
    "            row_['nodes'] = [e['id'] for e in context_pool]\n",
    "            row_['context'] = [json.loads(e['_node_content'])['text'] for e in context_pool]\n",
    "            row_['idx'] = str(uuid.uuid4())\n",
    "            fw.write(json.dumps(row_, ensure_ascii=False)+'\\n')\n",
    "\n",
    "            body = {\"model\": \"qwen-plus\", \"messages\": messages_builder_example((\n",
    "                \"根据以下提供的内容:\\n-----\\n\"+\n",
    "                \"\\n\".join(row_[\"context\"])+\n",
    "                \"\\n-----\\n提出一个根据上面的内容可以作答的问题，并给出这个问题的答案。问题要清晰具体，答案要简洁明了。总字数限制在200个字以内。\"\n",
    "            ))}\n",
    "            request = {\"custom_id\": row_['idx'], \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": body}\n",
    "            fout.write(json.dumps(request, separators=(',', ':'), ensure_ascii=False) + \"\\n\", )\n",
    "\n",
    "        prefix = '06ad4aec'\n",
    "        for _ in range(70):\n",
    "            start_idx = rnd.randint(0, 6900)\n",
    "            id_ = prefix+str(start_idx).zfill(8)\n",
    "            res = client.query(\n",
    "                collection_name=\"create_eval_dataset_collections\",\n",
    "                filter=f\"id like \\'{id_[:-2]}%\\'\"\n",
    "            )\n",
    "            ss = rnd.randint(1,50)\n",
    "            context_pool = [res[i] for i in range(ss, ss+rnd.randint(1,50))]\n",
    "            row_ = copy.deepcopy(format_basic)\n",
    "            row_['nodes'] = [e['id'] for e in context_pool]\n",
    "            row_['context'] = [json.loads(e['_node_content'])['text'] for e in context_pool]\n",
    "            row_['idx'] = str(uuid.uuid4())\n",
    "            fw.write(json.dumps(row_, ensure_ascii=False)+'\\n')\n",
    "\n",
    "            body = {\"model\": \"qwen-plus\", \"messages\": messages_builder_example((\n",
    "                \"根据以下提供的内容:\\n-----\\n\"+\n",
    "                \"\\n\".join(row_[\"context\"])+\n",
    "                \"\\n-----\\n提出一个根据上面的内容可以作答的问题，并给出这个问题的答案。总字数限制在200个字以内。\"\n",
    "            ))}\n",
    "            request = {\"custom_id\": row_['idx'], \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": body}\n",
    "            fout.write(json.dumps(request, separators=(',', ':'), ensure_ascii=False) + \"\\n\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "60c8c278-15ac-43ef-87d3-bb9f9be5b2ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-batch-ocBVvmfiJy7FP9Et9HwHPoMq', bytes=5725463, created_at=1735367490, filename='eval_dataset_text_basic.qwen.jsonl', object='file', purpose='batch', status='processed', status_details=None)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "\n",
    "dashscope_client = OpenAI(\n",
    "    # 若没有配置环境变量，可用百炼API Key将下行替换为：api_key=\"sk-xxx\"。但不建议在生产环境中直接将API Key硬编码到代码中，以减少API Key泄露风险。\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",  # 填写百炼服务的base_url\n",
    ")\n",
    "\n",
    "# test.jsonl 是一个本地示例文件，purpose必须是batch\n",
    "file_object = dashscope_client.files.create(file=Path('eval_dataset_text_basic.qwen.jsonl'), purpose=\"batch\")\n",
    "file_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "95f8aab3-28dc-4b15-ac74-3b480d10f049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(id='batch_91a58757-b5e0-43ce-8593-571a6ce96f40', completion_window='24h', created_at=1735367491, endpoint='/v1/chat/completions', input_file_id='file-batch-ocBVvmfiJy7FP9Et9HwHPoMq', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=None, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n"
     ]
    }
   ],
   "source": [
    "batch = dashscope_client.batches.create(\n",
    "    input_file_id=file_object.id,  # 上传文件返回的 id\n",
    "    endpoint=\"/v1/chat/completions\",  # 大语言模型固定填写，/v1/chat/completions\n",
    "    completion_window=\"24h\"  # 当前只支持24h，24小时未运行完会超时\n",
    ")\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "424926d1-be95-4516-8594-605f68fdf9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "while True:\n",
    "    try:\n",
    "        batch = dashscope_client.batches.retrieve(batch.id)  # 将batch_id替换为Batch任务的id\n",
    "        content = dashscope_client.files.content(file_id=batch.output_file_id)\n",
    "        # 打印结果文件内容\n",
    "        # print(content.text)\n",
    "        # 保存结果文件至本地\n",
    "        content.write_to_file(\"result.jsonl\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "826dc953-2214-4969-b774-9a03f740c0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ = []\n",
    "for ii in range(3):\n",
    "    with open(f'ss/eval_dataset_text_basic.{ii}.jsonl', 'r') as fr:\n",
    "        dataset = [json.loads(e) for e in fr.readlines()]\n",
    "    with open(f\"ss/result.{ii}.jsonl\", 'r') as fr:\n",
    "        qas = {json.loads(e)['custom_id']: json.loads(e) for e in fr.readlines()}\n",
    "    for row in dataset:\n",
    "        row_ = copy.deepcopy(row)\n",
    "        idx = row['idx']\n",
    "        if idx not in qas:\n",
    "            continue\n",
    "        text = qas[idx]['response']['body']['choices'][0]['message']['content']\n",
    "        assert '答案：' in text, print(text)\n",
    "        assert '问题：' in text, print(text)\n",
    "        row_['question'] = text.split('答案：')[0].split('问题：')[1].replace('\\n', '').replace('*', '')\n",
    "        row_['answer'] = text.split('答案：')[-1].replace('\\n', '').replace('*', '')\n",
    "        dataset_.append(json.dumps(row_, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4c1cb4bc-d631-4507-8606-3e500f4239a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 rows being recorded.\n"
     ]
    }
   ],
   "source": [
    "with open('../data/eval/eval_dataset_text_basic.jsonl', 'w') as fh:\n",
    "    print(f'{len(dataset_)} rows being recorded.')\n",
    "    fh.write('\\n'.join(dataset_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbbc9e0-03c8-4703-a806-4b20de2cb792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare advanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dd04e867-d3d4-44da-86be-7f08120a11fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_adv = {}\n",
    "with open('../data/eval/eval_dataset_text_adv.txt', 'r') as fh:\n",
    "    with open('../data/eval/eval_dataset_text_adv.jsonl', 'w') as fw:\n",
    "        raw_txt = fh.read()\n",
    "        qas = raw_txt.split('\\n\\n\\n\\n')\n",
    "        for qa in qas:\n",
    "            try:\n",
    "                q_, a_ = qa.split('a:')\n",
    "                fw.write(json.dumps({'question':q_, 'idx':str(uuid.uuid4()), 'answer':a_, \"nodes\":[], \"context\":[]}, ensure_ascii=False)+'\\n')\n",
    "            except Exception as e:\n",
    "                print(qa)\n",
    "                raise e\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bdc10f-cca3-4114-b3d3-3ad356c23fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
